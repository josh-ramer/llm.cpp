# llm.cpp
Making LLMs from scratch in CPP to build a more fundamental understanding of AI &amp; machines a la Karpathy. Things I plan on focusing on are as follows:

Iterations on CUDA GPU Kernels
   a. Add AMD, Metal, & other accelerators down the road.
Memory Efficiency & Management
     a. What are some of the ways different projects do this & why?
System Design
    a. Rewrite the code numerous times exploring the different design decisions.
    b. Static vs Dynamic computation graphs, is this something we need to think about?
    c. Can we write declaritive code in something like a DSL (ONNX) & then compile it into something fast?

